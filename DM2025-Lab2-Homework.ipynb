{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: WENG,YU-CHU\n",
    "\n",
    "Student ID: G13230105\n",
    "\n",
    "GitHub ID: Githhmax\n",
    "\n",
    "Kaggle name:Githumax\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "\n",
    "![pic_ranking.png](./git.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "**Syntax:** `#` creates the largest heading (H1).\n",
    "\n",
    "---\n",
    "**Syntax:** `---` creates a horizontal rule (a separator line).\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "**Syntax:** `##` creates a secondary heading (H2).\n",
    "\n",
    "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "**Syntax:** `###` creates a tertiary heading (H3).\n",
    "\n",
    "[Content for Preprocessing]\n",
    "\n",
    "**Example Syntax for Content:**\n",
    "*   **Bold text:** `**text**`\n",
    "*   *Italic text*: `*text*`\n",
    "*   Bullet point list:\n",
    "    * Item 1\n",
    "    * Item 2\n",
    "\n",
    "Markdown Syntax to Add Image: `![Description of the Image](./your_local_folder/name_of_the_image.png)`\n",
    "\n",
    "![Example Markdown Syntax to Add Image](./pics/example_md_img.png)\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "[Content for Feature Engineering]\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "[Content for Model Explanation]\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "**Add more detail in previous sections**\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "[Content for Experiments]\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "\n",
    "[Content for Insights]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Model Project Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preprocessing Steps : Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this stage is to convert raw, unstructured text data into a clean format that can be processed by the model.\n",
    "\n",
    "Data Cleaning and Standardization:\n",
    "* **Renaming Columns:** To ensure consistency in the code, the original text column ('text') is renamed to 'content'.\n",
    "* **Handling Missing Values:** All missing values (NaN) in the text column are replaced with empty strings (\"\") to prevent errors during the subsequent feature extraction process.\n",
    "\n",
    "The text cleaning function performs the following key steps:\n",
    "* **Lowercasing:** All text is converted to lowercase to standardize the word form.\n",
    "* **Removing URLs:** All URLs (in http or www format) are removed, as they typically do not contain sentiment information.\n",
    "* **Removing Non-Alphabetic Characters:** All numbers and punctuation marks are removed, leaving only English letters (a-z) and spaces, in order to reduce noise and dimensionality in the feature space.\n",
    "* **Standardizing Spaces:** Extra consecutive spaces are removed to ensure the text format is clean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature Engineering Steps: TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses an optimized Term Frequency-Inverse Document Frequency (TF-IDF) method to convert the cleaned text into sparse vectors with 10,000 dimensions.\n",
    "\n",
    "* **Function of TF-IDF:** TF-IDF is a weighting method that effectively quantifies the importance of a word within a single document, while balancing its generality across the entire dataset.\n",
    "* **Key Parameter Configuration:**\n",
    "    * **N-gram Range:** Set ngram_range=(1, 2) to extract both unigrams (single words) and bigrams (consecutive word pairs). \n",
    "        This helps capture the semantics of negative or negation phrases (e.g., \"not happy\").\n",
    "    * **Feature Limitation:** Set max_features=10000 to limit the final feature dimensions, balancing model complexity with computational cost.\n",
    "    * **Sublinear Term Frequency Scaling:** Enabling sublinear_tf=True uses 1+log *(TF)* to replace the raw term frequency *(TF)*.\n",
    "        * **Note:** This smooths the influence of high-frequency terms, preventing a few extremely high-frequency terms from dominating the feature weights.\n",
    "* **Feature Matrix Dimensions:** After the TF-IDF transformation, the data dimensions are as follows:\n",
    "\n",
    "    ![pic_ranking.png](./222.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Explanation of Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses Linear Support Vector Machine (Linear SVM) as the base classification model.\n",
    "It is implemented using the **SGDClassifier** with the loss function set to **loss='hinge'**.\n",
    "* **Reason for Choice:**\n",
    "Linear SVM is efficient for handling high-dimensional, sparse TF-IDF features. It trains quickly and can effectively find the separating hyperplane with the maximum margin between sentiment categories.\n",
    "* **Handling Class Imbalance:**\n",
    "The parameter class_weight='balanced' is set to automatically adjust the weights based on the sample distribution of each sentiment category. This key configuration aims to increase the model's sensitivity to minority classes (e.g., Disgust, Fear).\n",
    "* **Validation and Evaluation:**\n",
    "20% of the training data is set aside as a validation set, and stratified sampling (stratify=y_labels) is used to ensure consistent class proportions.\n",
    "* **Evaluation Metric:**\n",
    "The evaluation metric is the Macro F1 Score, which is more reliable than Accuracy for class-imbalanced problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Model Evaluation Results:**\n",
    "Validation Mean F1 Score: 0.4239\n",
    "* **Classification Report:**   \n",
    "![pic_ranking.png](./333.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bonus Section \n",
    "\n",
    "### 2.1 Mention Different Things You Tried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Critical Parameter Tuning for TF-IDF**\n",
    "\n",
    "**Retaining Negation Words:**\n",
    " * Changing the setting from stop_words='english' to stop_words=None successfully resolved sentiment polarity errors caused by removing negation words such as “not.”\n",
    "\n",
    " **N-gram / Max Feature Experiments:**\n",
    "* Based on the original configuration of ngram_range=(1, 2) and max_features=10000, experiments were conducted by expanding the N-gram range (up to 1, 3) or increasing the number of features (up to 20,000). However, the results showed that retaining negation words was the key factor contributing to performance improvement.\n",
    " \n",
    " **2. Model Tuning**\n",
    " * Using grid search, we systematically tuned the key hyperparameter ($\\alpha$)  of the Linear SVM to prevent overfitting and maximize the Macro F1 Score on the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Mention Insights You Gained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of Multi-Feature Fusion:**\n",
    "* The addition of structural features effectively improved the F1-scores for strong-emotion categories such as Anger and Joy. Retaining stop words also successfully resolved polarity detection issues in negation sentences.\n",
    "\n",
    "**Challenges with Sparse Classes (Disgust):**\n",
    "* Disgust (F1-score 0.15) performed poorly due to having the smallest number of samples (237). Future improvements may include applying data augmentation techniques or using loss functions such as Focal Loss to address this issue.\n",
    "\n",
    "**Recall/Precision Trade-off (Fear):**\n",
    "* The high recall (0.63) and low precision (0.25) for the Fear category indicate that the model tends to overgeneralize, often misclassifying other emotions as “fear.” This may be related to the semantic overlap between fear and sadness or anger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Kaggle Leaderboard Result:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic_ranking.png](./2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic_ranking.png](./4.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![pic_ranking.png](./3.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Read and parse the JSON file (simultaneously renaming 'text' to 'content')\n",
    "posts = pd.DataFrame([x['_source']['post'] for x in pd.read_json('/kaggle/input/final_posts.json')['root']]).rename(columns={'tweet_id': 'post_id', 'text': 'content'})\n",
    "\n",
    "# Read the ID identification file and merge it with the posts\n",
    "# Renames 'id' to 'post_id' to allow merging\n",
    "data = pd.read_csv('/kaggle/input/data_identification.csv').rename(columns={'id': 'post_id'}).merge(posts, on='post_id')\n",
    "\n",
    "# Generate train_df (Merge with emotion labels/ground truth)\n",
    "train_df = data[data['split'] == 'train'].merge(pd.read_csv('/kaggle/input/emotion.csv').rename(columns={'id': 'post_id'}), on='post_id')\n",
    "\n",
    "# Generate test_df\n",
    "test_df = data[data['split'] == 'test']\n",
    "\n",
    "print(train_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Ensure column name consistency (rename the original 'text' column to 'content')\n",
    "if 'text' in train_df.columns:\n",
    "    train_df = train_df.rename(columns={'text': 'content'})\n",
    "if 'text' in test_df.columns:\n",
    "    test_df = test_df.rename(columns={'text': 'content'})\n",
    "\n",
    "# 1.2 Handle Missing Values (Missing Values)\n",
    "# There may be NaN values in the text data, which must be replaced with empty strings.\n",
    "train_df['content'] = train_df['content'].fillna(\"\")\n",
    "test_df['content'] = test_df['content'].fillna(\"\")\n",
    "\n",
    "# 1.3 Define a text cleaning function\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove Punctuation & Numbers\n",
    "    # Keep only English letters (a–z) and spaces\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 1.4 Apply Text Cleaning Function\n",
    "train_df['cleaned_text'] = train_df['content'].apply(clean_text)\n",
    "test_df['cleaned_text'] = test_df['content'].apply(clean_text)\n",
    "\n",
    "display(train_df[['content', 'cleaned_text']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Initialize TF-IDF Vectorizer\n",
    "# Consider both single words (unigrams) and two-word combinations (bigrams), e.g., \"not happy\"\n",
    "# Remove meaningless stopwords.\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=10000, # To reduce excessive noise\n",
    "    stop_words=None,\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode'\n",
    ")\n",
    "\n",
    "# 2.2 Transform the data \n",
    "# Use fit_transform on the training set (learn the vocabulary and transform the data)\n",
    "X_features = tfidf.fit_transform(train_df['cleaned_text'])\n",
    "\n",
    "# For the test set, use transform only (convert using the vocabulary learned from the training set)\n",
    "X_test_features = tfidf.transform(test_df['cleaned_text'])\n",
    "\n",
    "# Prepare the labels (Target)\n",
    "y_labels = train_df['emotion']\n",
    "\n",
    "print(f\"Training feature matrix shape: {X_features.shape}\")\n",
    "print(f\"Testing feature matrix shape: {X_test_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Validation Split\n",
    "# Hold out 20% of the training data as a validation set to evaluate the model’s performance\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_features, y_labels, test_size=0.2, random_state=42, stratify=y_labels\n",
    ")\n",
    "\n",
    "# 3.2 Define the model (Linear SVM)\n",
    "# class_weight='balanced': Automatically adjust class weights to handle imbalanced emotion samples\n",
    "model = SGDClassifier(\n",
    "    loss='hinge',\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3.3 Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3.4 Model Evaluation\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "# Compute Macro F1 Score\n",
    "val_f1 = f1_score(y_val, y_pred_val, average='macro')\n",
    "print(f\"\\n Validation Mean F1 Score: {val_f1:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 3.5 Prediction on Test Set\n",
    "# Retrain using the entire dataset\n",
    "final_predictions = model.predict(X_test_features)\n",
    "\n",
    "# 3.6 Create the Submission File\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['post_id'],  \n",
    "    'emotion': final_predictions\n",
    "})\n",
    "\n",
    "# final:Save as CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "display(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
